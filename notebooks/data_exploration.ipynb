{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PART1 DATA EXPLORATION"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_dir = Path('../data')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_path = data_dir / 'Dataset1.csv'\n",
    "df = pd.read_csv(data_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Explore the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head(50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def check_weird_values(data):\n",
    "    for col in data.columns:\n",
    "        try:\n",
    "            data[col] = data[col].astype(float)\n",
    "        except ValueError as err:\n",
    "            print(f'could not convert data on column \"{col}\" with error {err}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check_weird_values(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def check_duplicated(data: pd.DataFrame):\n",
    "    if num_duplicated := sum(data.duplicated()):\n",
    "        print(f'df has {num_duplicated} duplicated rows')\n",
    "    else:\n",
    "        print('data frame has no duplicated rows')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check_duplicated(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check for empty values\n",
    "print(\"\\nNumber of empty values in each column:\")\n",
    "print(df.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Cleaning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_rows_with_errors(input_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    error_rows = []\n",
    "\n",
    "    for col in input_df.columns:\n",
    "        try:\n",
    "            input_df[col] = input_df[col].astype(float)\n",
    "        except ValueError as e:\n",
    "            print(f'could not convert data on column \"{col}\" with error {e}')\n",
    "            error_rows.extend(input_df[col][pd.to_numeric(input_df[col], errors='coerce').isna()].index.tolist())\n",
    "\n",
    "    error_rows = np.unique(error_rows)\n",
    "    df_cleaned = df.drop(index=error_rows)\n",
    "    print(f'removed rows are : {error_rows}')\n",
    "\n",
    "    return df_cleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_duplicates_from_dataframe(input_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    seen_rows = set()\n",
    "    output_rows = []\n",
    "\n",
    "    for index, row in input_df.iterrows():\n",
    "        row_tuple = tuple(row)\n",
    "        if row_tuple not in seen_rows:\n",
    "            seen_rows.add(row_tuple)\n",
    "            output_rows.append(row)\n",
    "\n",
    "    output_df = pd.DataFrame(output_rows, columns=input_df.columns)\n",
    "    return output_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_rows_with_missing_values(input_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    output_df = input_df[~input_df.isna().any(axis=1)]\n",
    "    return output_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def clean_df(input_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    input_df = remove_rows_with_errors(input_df)\n",
    "    input_df = remove_duplicates_from_dataframe(input_df)\n",
    "    input_df = remove_rows_with_missing_values(input_df)\n",
    "    return input_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = clean_df(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check_duplicated(df)\n",
    "check_weird_values(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data description"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def global_describe(input_data):\n",
    "    \"\"\"\n",
    "    Provide a simple global description for a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pandas.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the number of rows, number of columns, and data type of each column.\n",
    "    \"\"\"\n",
    "    num_rows = len(input_data)\n",
    "    num_columns = len(input_data.columns)\n",
    "    column_types = input_data.dtypes.to_dict()\n",
    "\n",
    "    global_desc = {\n",
    "        'num_rows': num_rows,\n",
    "        'num_columns': num_columns,\n",
    "        'column_types': column_types,\n",
    "    }\n",
    "\n",
    "    return global_desc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pprint(global_describe(df))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def custom_describe(input_df: pd.DataFrame):\n",
    "    result = {}\n",
    "\n",
    "    for column in input_df.columns:\n",
    "        values = input_df[column].tolist()\n",
    "        sorted_values = sorted(values)\n",
    "        # Maximum\n",
    "        max_val = max(values)\n",
    "\n",
    "        # Minimum\n",
    "        min_val = min(values)\n",
    "\n",
    "        # Mean\n",
    "        mean = sum(values) / len(values)\n",
    "\n",
    "        # Mode\n",
    "        counter = Counter(input_df[column])\n",
    "        mode = counter.most_common(1)[0][0]\n",
    "\n",
    "        # Median\n",
    "        n = len(sorted_values)\n",
    "        if n % 2 == 0:\n",
    "            median = (sorted_values[n // 2 - 1] + sorted_values[n // 2]) / 2\n",
    "        else:\n",
    "            median = sorted_values[n // 2]\n",
    "\n",
    "        # Standard Deviation\n",
    "        std_val = (sum((x - mean) ** 2 for x in values) / len(values)) ** 0.5\n",
    "\n",
    "        # Quantiles\n",
    "        quantiles = {\n",
    "            '25%': sorted_values[int(0.25 * n)],\n",
    "            '50%': median,\n",
    "            '75%': sorted_values[int(0.75 * n)]\n",
    "        }\n",
    "\n",
    "        result[column] = {\n",
    "            'max': max_val,\n",
    "            'min': min_val,\n",
    "            'mean': mean,\n",
    "            'mode': mode,\n",
    "            'median': median,\n",
    "            'std': std_val,\n",
    "            'quantiles': quantiles\n",
    "        }\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pprint(custom_describe(df))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_cols = len(df.columns)\n",
    "num_rows = (num_cols + 1) // 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=num_rows, ncols=2, figsize=(12, 5 * num_rows))\n",
    "fig.suptitle('Box plots of Data')\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, column in enumerate(df.columns):\n",
    "    ax = sns.boxplot(y=df[column], ax=axes[i])\n",
    "    axes[i].set_title(column)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(num_rows, 2, figsize=(15, num_rows * 4))\n",
    "fig.suptitle('Histograms of Data', y=1.02)\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(df.columns):\n",
    "    sns.histplot(df[col], ax=axes[i], kde=True)\n",
    "    axes[i].set_title(f'Histogram for {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(num_rows, 2, figsize=(15, num_rows * 4))\n",
    "fig.suptitle('Scatter Plots of Data', y=1.02)\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(df.columns):\n",
    "    sns.scatterplot(df[col], ax=axes[i])\n",
    "    axes[i].set_title(f'Histogram for {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
